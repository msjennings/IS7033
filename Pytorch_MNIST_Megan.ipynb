{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://nextjournal.com/gkoehler/pytorch-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1ac6c525db0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size_train = 1000\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 1\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Makes Train & Test data set\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    #This defines the structure of the NN.\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()  #Dropout\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Convolutional Layer/Pooling Layer/Activation\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2)) \n",
    "        #Convolutional Layer/Dropout/Pooling Layer/Activation\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        #Fully Connected Layer/Activation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        #Fully Connected Layer/Activation\n",
    "        x = self.fc2(x)\n",
    "        #Softmax gets probabilities. \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "                (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            #torch.save(network.state_dict(), '/results/model.pth')\n",
    "            #torch.save(optimizer.state_dict(), '/results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pli6894\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3316, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.345348\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 2.352634\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.342667\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 2.338256\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.330323\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 2.325202\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 2.335884\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 2.316394\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 2.318127\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 2.322156\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 2.309714\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 2.303674\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 2.310961\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 2.306022\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 2.305056\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 2.302761\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.299080\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 2.291515\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 2.293934\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 2.284221\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 2.286136\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 2.293048\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 2.289628\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 2.285886\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 2.284266\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 2.285401\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 2.283351\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 2.279167\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 2.275277\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 2.283229\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 2.282371\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 2.276048\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.266374\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 2.275102\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 2.278504\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 2.269106\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 2.269558\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 2.271079\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 2.260385\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 2.263268\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 2.263417\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 2.252854\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 2.252054\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 2.263284\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 2.259033\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 2.256570\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 2.250679\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 2.248216\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 2.253401\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 2.241069\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 2.237114\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 2.231260\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 2.240975\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 2.226020\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 2.220469\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 2.225295\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 2.216296\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 2.217590\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 2.216485\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 2.203332\n",
      "\n",
      "Test set: Avg. loss: 2.1822, Accuracy: 3577/10000 (35%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.205902\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 2.205475\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 2.201324\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 2.205210\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 2.194401\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 2.189343\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 2.187360\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 2.180107\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 2.179025\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 2.175934\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 2.161713\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 2.153242\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 2.166411\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 2.152774\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 2.147438\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 2.143797\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 2.118893\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 2.131759\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 2.118371\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 2.114971\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 2.090961\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 2.105410\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 2.078298\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 2.092481\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 2.085101\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 2.076664\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 2.076491\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 2.068648\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 2.046632\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 2.048531\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 2.012316\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 2.012109\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 2.025644\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 2.019509\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 1.978306\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 1.999640\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 1.978275\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 1.965848\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 1.977083\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 1.941383\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 1.953972\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 1.949682\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 1.928888\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 1.948766\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 1.888747\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 1.930905\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 1.861965\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 1.919371\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 1.889907\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 1.860100\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 1.857880\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 1.857296\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 1.817053\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 1.828544\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 1.820728\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 1.827214\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 1.797960\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 1.793209\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 1.798639\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 1.779360\n",
      "\n",
      "Test set: Avg. loss: 1.5534, Accuracy: 6447/10000 (64%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.763349\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 1.712263\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 1.741425\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 1.700500\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 1.712894\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 1.726914\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 1.720291\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 1.682075\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 1.669167\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 1.666934\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 1.650324\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 1.636781\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 1.649246\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 1.654967\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 1.644652\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 1.638152\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 1.656523\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 1.627946\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 1.600901\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 1.552167\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 1.561821\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 1.532240\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 1.524408\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 1.528924\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 1.506376\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 1.510522\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 1.514698\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 1.509032\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 1.527838\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 1.504539\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 1.476303\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 1.458710\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.465556\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 1.418911\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 1.435256\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 1.416176\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 1.374508\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 1.413982\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 1.381654\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 1.384691\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 1.424927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 1.398848\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 1.422527\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 1.407525\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 1.358191\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 1.334724\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 1.391779\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 1.292787\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 1.342624\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 1.332114\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 1.370897\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 1.321436\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 1.327854\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 1.323862\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 1.270376\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 1.293220\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 1.237430\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 1.243260\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 1.193199\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 1.291793\n",
      "\n",
      "Test set: Avg. loss: 0.8579, Accuracy: 8152/10000 (81%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.250196\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 1.274819\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 1.234532\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 1.163568\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 1.260682\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 1.198102\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 1.191918\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 1.214500\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 1.206134\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 1.110862\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 1.232027\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 1.169778\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 1.195486\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 1.136157\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 1.118569\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 1.206884\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 1.141700\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 1.135454\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 1.158754\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 1.104450\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 1.144047\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 1.058505\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 1.113659\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 1.085992\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 1.102100\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 1.089486\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 1.071553\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 1.104406\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 1.088747\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 1.058704\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 1.110315\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 1.051963\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 1.042307\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 1.007418\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 1.039663\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 1.030248\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 1.015503\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 1.060889\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 1.049242\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 1.042374\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 1.016537\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.971100\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 1.081036\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 1.038160\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 1.039716\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 1.055372\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.965618\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.965794\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.990792\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 1.036828\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.966335\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 1.042603\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.988164\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.973326\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.970086\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.935070\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.935935\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.930063\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.993895\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.898432\n",
      "\n",
      "Test set: Avg. loss: 0.5555, Accuracy: 8644/10000 (86%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.943500\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.995189\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.906805\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.902015\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.950517\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.878741\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.950989\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.909051\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.892299\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.921801\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.880429\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.931176\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.880239\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.864660\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.940002\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.890232\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.885759\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.952345\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.890228\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.893639\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.861856\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.872603\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.931770\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.871727\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.815147\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.881941\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.916457\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.879985\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.899794\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.871131\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.897501\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.864346\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.912108\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.908242\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.852322\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.847904\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.877159\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.862011\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.900312\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.834674\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.893413\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.795103\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.798642\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.834854\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.835737\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.883696\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.840508\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.824771\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.850513\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.836006\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.815567\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.848080\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.803196\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.801990\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.808025\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.832969\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.832789\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.826432\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.810583\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.794100\n",
      "\n",
      "Test set: Avg. loss: 0.4481, Accuracy: 8791/10000 (87%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.862664\n",
      "Train Epoch: 6 [1000/60000 (2%)]\tLoss: 0.839905\n",
      "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 0.832858\n",
      "Train Epoch: 6 [3000/60000 (5%)]\tLoss: 0.839729\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 0.814534\n",
      "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 0.783716\n",
      "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 0.749816\n",
      "Train Epoch: 6 [7000/60000 (12%)]\tLoss: 0.841293\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 0.736839\n",
      "Train Epoch: 6 [9000/60000 (15%)]\tLoss: 0.794253\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.816115\n",
      "Train Epoch: 6 [11000/60000 (18%)]\tLoss: 0.789515\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.753303\n",
      "Train Epoch: 6 [13000/60000 (22%)]\tLoss: 0.730587\n",
      "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 0.801067\n",
      "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 0.826187\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.736694\n",
      "Train Epoch: 6 [17000/60000 (28%)]\tLoss: 0.763647\n",
      "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 0.846087\n",
      "Train Epoch: 6 [19000/60000 (32%)]\tLoss: 0.802750\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.689600\n",
      "Train Epoch: 6 [21000/60000 (35%)]\tLoss: 0.820266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 0.750948\n",
      "Train Epoch: 6 [23000/60000 (38%)]\tLoss: 0.731035\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.820895\n",
      "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 0.795601\n",
      "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 0.733222\n",
      "Train Epoch: 6 [27000/60000 (45%)]\tLoss: 0.748221\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 0.822270\n",
      "Train Epoch: 6 [29000/60000 (48%)]\tLoss: 0.696019\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.802267\n",
      "Train Epoch: 6 [31000/60000 (52%)]\tLoss: 0.764353\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.676139\n",
      "Train Epoch: 6 [33000/60000 (55%)]\tLoss: 0.705811\n",
      "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 0.735171\n",
      "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 0.747613\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.808977\n",
      "Train Epoch: 6 [37000/60000 (62%)]\tLoss: 0.763416\n",
      "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 0.714286\n",
      "Train Epoch: 6 [39000/60000 (65%)]\tLoss: 0.794743\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.710530\n",
      "Train Epoch: 6 [41000/60000 (68%)]\tLoss: 0.771322\n",
      "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 0.708409\n",
      "Train Epoch: 6 [43000/60000 (72%)]\tLoss: 0.733006\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 0.781319\n",
      "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 0.712143\n",
      "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 0.774456\n",
      "Train Epoch: 6 [47000/60000 (78%)]\tLoss: 0.795773\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.733231\n",
      "Train Epoch: 6 [49000/60000 (82%)]\tLoss: 0.775033\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.680311\n",
      "Train Epoch: 6 [51000/60000 (85%)]\tLoss: 0.776119\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 0.733728\n",
      "Train Epoch: 6 [53000/60000 (88%)]\tLoss: 0.773924\n",
      "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 0.743108\n",
      "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 0.688234\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 0.735446\n",
      "Train Epoch: 6 [57000/60000 (95%)]\tLoss: 0.726316\n",
      "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 0.726307\n",
      "Train Epoch: 6 [59000/60000 (98%)]\tLoss: 0.750489\n",
      "\n",
      "Test set: Avg. loss: 0.3806, Accuracy: 8950/10000 (89%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.723504\n",
      "Train Epoch: 7 [1000/60000 (2%)]\tLoss: 0.709724\n",
      "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 0.734635\n",
      "Train Epoch: 7 [3000/60000 (5%)]\tLoss: 0.739400\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 0.704197\n",
      "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 0.706299\n",
      "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 0.669746\n",
      "Train Epoch: 7 [7000/60000 (12%)]\tLoss: 0.678412\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 0.677434\n",
      "Train Epoch: 7 [9000/60000 (15%)]\tLoss: 0.758619\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.786366\n",
      "Train Epoch: 7 [11000/60000 (18%)]\tLoss: 0.699937\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.755213\n",
      "Train Epoch: 7 [13000/60000 (22%)]\tLoss: 0.676513\n",
      "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 0.676398\n",
      "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 0.729855\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.643535\n",
      "Train Epoch: 7 [17000/60000 (28%)]\tLoss: 0.696057\n",
      "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 0.684153\n",
      "Train Epoch: 7 [19000/60000 (32%)]\tLoss: 0.653055\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.710113\n",
      "Train Epoch: 7 [21000/60000 (35%)]\tLoss: 0.666136\n",
      "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 0.676676\n",
      "Train Epoch: 7 [23000/60000 (38%)]\tLoss: 0.776224\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.720996\n",
      "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 0.681695\n",
      "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 0.687727\n",
      "Train Epoch: 7 [27000/60000 (45%)]\tLoss: 0.657875\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 0.643260\n",
      "Train Epoch: 7 [29000/60000 (48%)]\tLoss: 0.695345\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.661923\n",
      "Train Epoch: 7 [31000/60000 (52%)]\tLoss: 0.677044\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.693787\n",
      "Train Epoch: 7 [33000/60000 (55%)]\tLoss: 0.703664\n",
      "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 0.670041\n",
      "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 0.740511\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.710507\n",
      "Train Epoch: 7 [37000/60000 (62%)]\tLoss: 0.659761\n",
      "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 0.710237\n",
      "Train Epoch: 7 [39000/60000 (65%)]\tLoss: 0.685196\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.669231\n",
      "Train Epoch: 7 [41000/60000 (68%)]\tLoss: 0.640462\n",
      "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 0.668669\n",
      "Train Epoch: 7 [43000/60000 (72%)]\tLoss: 0.711143\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 0.658500\n",
      "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 0.652932\n",
      "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 0.656406\n",
      "Train Epoch: 7 [47000/60000 (78%)]\tLoss: 0.681588\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.623166\n",
      "Train Epoch: 7 [49000/60000 (82%)]\tLoss: 0.667303\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.682005\n",
      "Train Epoch: 7 [51000/60000 (85%)]\tLoss: 0.608391\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 0.652270\n",
      "Train Epoch: 7 [53000/60000 (88%)]\tLoss: 0.748174\n",
      "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 0.688803\n",
      "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 0.732646\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 0.654493\n",
      "Train Epoch: 7 [57000/60000 (95%)]\tLoss: 0.659586\n",
      "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 0.687993\n",
      "Train Epoch: 7 [59000/60000 (98%)]\tLoss: 0.681542\n",
      "\n",
      "Test set: Avg. loss: 0.3442, Accuracy: 9065/10000 (90%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.634250\n",
      "Train Epoch: 8 [1000/60000 (2%)]\tLoss: 0.663150\n",
      "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 0.672954\n",
      "Train Epoch: 8 [3000/60000 (5%)]\tLoss: 0.633513\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 0.714564\n",
      "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 0.659660\n",
      "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 0.675684\n",
      "Train Epoch: 8 [7000/60000 (12%)]\tLoss: 0.639551\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 0.603751\n",
      "Train Epoch: 8 [9000/60000 (15%)]\tLoss: 0.646211\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.707830\n",
      "Train Epoch: 8 [11000/60000 (18%)]\tLoss: 0.599109\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.628500\n",
      "Train Epoch: 8 [13000/60000 (22%)]\tLoss: 0.638875\n",
      "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 0.711617\n",
      "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 0.621969\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.700478\n",
      "Train Epoch: 8 [17000/60000 (28%)]\tLoss: 0.642872\n",
      "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 0.647036\n",
      "Train Epoch: 8 [19000/60000 (32%)]\tLoss: 0.724891\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.645662\n",
      "Train Epoch: 8 [21000/60000 (35%)]\tLoss: 0.631307\n",
      "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 0.658028\n",
      "Train Epoch: 8 [23000/60000 (38%)]\tLoss: 0.595576\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.651398\n",
      "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 0.677214\n",
      "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 0.660306\n",
      "Train Epoch: 8 [27000/60000 (45%)]\tLoss: 0.579529\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 0.611547\n",
      "Train Epoch: 8 [29000/60000 (48%)]\tLoss: 0.638707\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.586843\n",
      "Train Epoch: 8 [31000/60000 (52%)]\tLoss: 0.649188\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.608124\n",
      "Train Epoch: 8 [33000/60000 (55%)]\tLoss: 0.594734\n",
      "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 0.537463\n",
      "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 0.641900\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.608486\n",
      "Train Epoch: 8 [37000/60000 (62%)]\tLoss: 0.629816\n",
      "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 0.641707\n",
      "Train Epoch: 8 [39000/60000 (65%)]\tLoss: 0.636155\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.638943\n",
      "Train Epoch: 8 [41000/60000 (68%)]\tLoss: 0.621543\n",
      "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 0.603209\n",
      "Train Epoch: 8 [43000/60000 (72%)]\tLoss: 0.639105\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 0.643919\n",
      "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 0.667937\n",
      "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 0.618300\n",
      "Train Epoch: 8 [47000/60000 (78%)]\tLoss: 0.627578\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.571759\n",
      "Train Epoch: 8 [49000/60000 (82%)]\tLoss: 0.581659\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.669301\n",
      "Train Epoch: 8 [51000/60000 (85%)]\tLoss: 0.644562\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 0.581199\n",
      "Train Epoch: 8 [53000/60000 (88%)]\tLoss: 0.597946\n",
      "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 0.659072\n",
      "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 0.663494\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 0.602794\n",
      "Train Epoch: 8 [57000/60000 (95%)]\tLoss: 0.629846\n",
      "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 0.604692\n",
      "Train Epoch: 8 [59000/60000 (98%)]\tLoss: 0.599782\n",
      "\n",
      "Test set: Avg. loss: 0.3115, Accuracy: 9130/10000 (91%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.632241\n",
      "Train Epoch: 9 [1000/60000 (2%)]\tLoss: 0.619453\n",
      "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 0.640968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [3000/60000 (5%)]\tLoss: 0.624551\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 0.611396\n",
      "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 0.625208\n",
      "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 0.574428\n",
      "Train Epoch: 9 [7000/60000 (12%)]\tLoss: 0.651605\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 0.537624\n",
      "Train Epoch: 9 [9000/60000 (15%)]\tLoss: 0.627601\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.596804\n",
      "Train Epoch: 9 [11000/60000 (18%)]\tLoss: 0.635121\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.605281\n",
      "Train Epoch: 9 [13000/60000 (22%)]\tLoss: 0.618356\n",
      "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 0.559198\n",
      "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 0.630130\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.642749\n",
      "Train Epoch: 9 [17000/60000 (28%)]\tLoss: 0.610767\n",
      "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 0.598444\n",
      "Train Epoch: 9 [19000/60000 (32%)]\tLoss: 0.559390\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.565741\n",
      "Train Epoch: 9 [21000/60000 (35%)]\tLoss: 0.681993\n",
      "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 0.641449\n",
      "Train Epoch: 9 [23000/60000 (38%)]\tLoss: 0.600007\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.627055\n",
      "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 0.615345\n",
      "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 0.575475\n",
      "Train Epoch: 9 [27000/60000 (45%)]\tLoss: 0.623019\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 0.542344\n",
      "Train Epoch: 9 [29000/60000 (48%)]\tLoss: 0.558751\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.572243\n",
      "Train Epoch: 9 [31000/60000 (52%)]\tLoss: 0.610775\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.564029\n",
      "Train Epoch: 9 [33000/60000 (55%)]\tLoss: 0.607230\n",
      "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 0.612167\n",
      "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 0.517769\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.576358\n",
      "Train Epoch: 9 [37000/60000 (62%)]\tLoss: 0.566300\n",
      "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 0.609748\n",
      "Train Epoch: 9 [39000/60000 (65%)]\tLoss: 0.592274\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.583626\n",
      "Train Epoch: 9 [41000/60000 (68%)]\tLoss: 0.599221\n",
      "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 0.658446\n",
      "Train Epoch: 9 [43000/60000 (72%)]\tLoss: 0.568666\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 0.556016\n",
      "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 0.611627\n",
      "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 0.625455\n",
      "Train Epoch: 9 [47000/60000 (78%)]\tLoss: 0.591172\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.630046\n",
      "Train Epoch: 9 [49000/60000 (82%)]\tLoss: 0.528814\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.549322\n",
      "Train Epoch: 9 [51000/60000 (85%)]\tLoss: 0.598602\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 0.562505\n",
      "Train Epoch: 9 [53000/60000 (88%)]\tLoss: 0.641401\n",
      "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 0.506857\n",
      "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 0.519238\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 0.565832\n",
      "Train Epoch: 9 [57000/60000 (95%)]\tLoss: 0.541177\n",
      "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 0.598297\n",
      "Train Epoch: 9 [59000/60000 (98%)]\tLoss: 0.540532\n",
      "\n",
      "Test set: Avg. loss: 0.2837, Accuracy: 9186/10000 (91%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.640296\n",
      "Train Epoch: 10 [1000/60000 (2%)]\tLoss: 0.566895\n",
      "Train Epoch: 10 [2000/60000 (3%)]\tLoss: 0.576083\n",
      "Train Epoch: 10 [3000/60000 (5%)]\tLoss: 0.569840\n",
      "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 0.526206\n",
      "Train Epoch: 10 [5000/60000 (8%)]\tLoss: 0.631205\n",
      "Train Epoch: 10 [6000/60000 (10%)]\tLoss: 0.573671\n",
      "Train Epoch: 10 [7000/60000 (12%)]\tLoss: 0.578020\n",
      "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 0.606633\n",
      "Train Epoch: 10 [9000/60000 (15%)]\tLoss: 0.559906\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 0.613735\n",
      "Train Epoch: 10 [11000/60000 (18%)]\tLoss: 0.587860\n",
      "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 0.572441\n",
      "Train Epoch: 10 [13000/60000 (22%)]\tLoss: 0.557940\n",
      "Train Epoch: 10 [14000/60000 (23%)]\tLoss: 0.538790\n",
      "Train Epoch: 10 [15000/60000 (25%)]\tLoss: 0.604381\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.562160\n",
      "Train Epoch: 10 [17000/60000 (28%)]\tLoss: 0.569145\n",
      "Train Epoch: 10 [18000/60000 (30%)]\tLoss: 0.533213\n",
      "Train Epoch: 10 [19000/60000 (32%)]\tLoss: 0.522685\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.546795\n",
      "Train Epoch: 10 [21000/60000 (35%)]\tLoss: 0.570832\n",
      "Train Epoch: 10 [22000/60000 (37%)]\tLoss: 0.503229\n",
      "Train Epoch: 10 [23000/60000 (38%)]\tLoss: 0.586798\n",
      "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 0.526723\n",
      "Train Epoch: 10 [25000/60000 (42%)]\tLoss: 0.568738\n",
      "Train Epoch: 10 [26000/60000 (43%)]\tLoss: 0.562169\n",
      "Train Epoch: 10 [27000/60000 (45%)]\tLoss: 0.536794\n",
      "Train Epoch: 10 [28000/60000 (47%)]\tLoss: 0.602341\n",
      "Train Epoch: 10 [29000/60000 (48%)]\tLoss: 0.588018\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 0.607495\n",
      "Train Epoch: 10 [31000/60000 (52%)]\tLoss: 0.622016\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.584193\n",
      "Train Epoch: 10 [33000/60000 (55%)]\tLoss: 0.521378\n",
      "Train Epoch: 10 [34000/60000 (57%)]\tLoss: 0.523471\n",
      "Train Epoch: 10 [35000/60000 (58%)]\tLoss: 0.556037\n",
      "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 0.574976\n",
      "Train Epoch: 10 [37000/60000 (62%)]\tLoss: 0.542048\n",
      "Train Epoch: 10 [38000/60000 (63%)]\tLoss: 0.555388\n",
      "Train Epoch: 10 [39000/60000 (65%)]\tLoss: 0.571326\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.542666\n",
      "Train Epoch: 10 [41000/60000 (68%)]\tLoss: 0.549464\n",
      "Train Epoch: 10 [42000/60000 (70%)]\tLoss: 0.600891\n",
      "Train Epoch: 10 [43000/60000 (72%)]\tLoss: 0.545485\n",
      "Train Epoch: 10 [44000/60000 (73%)]\tLoss: 0.510925\n",
      "Train Epoch: 10 [45000/60000 (75%)]\tLoss: 0.536561\n",
      "Train Epoch: 10 [46000/60000 (77%)]\tLoss: 0.554784\n",
      "Train Epoch: 10 [47000/60000 (78%)]\tLoss: 0.506056\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.556631\n",
      "Train Epoch: 10 [49000/60000 (82%)]\tLoss: 0.495249\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 0.533550\n",
      "Train Epoch: 10 [51000/60000 (85%)]\tLoss: 0.556858\n",
      "Train Epoch: 10 [52000/60000 (87%)]\tLoss: 0.561959\n",
      "Train Epoch: 10 [53000/60000 (88%)]\tLoss: 0.534109\n",
      "Train Epoch: 10 [54000/60000 (90%)]\tLoss: 0.499434\n",
      "Train Epoch: 10 [55000/60000 (92%)]\tLoss: 0.649733\n",
      "Train Epoch: 10 [56000/60000 (93%)]\tLoss: 0.586424\n",
      "Train Epoch: 10 [57000/60000 (95%)]\tLoss: 0.484026\n",
      "Train Epoch: 10 [58000/60000 (97%)]\tLoss: 0.566614\n",
      "Train Epoch: 10 [59000/60000 (98%)]\tLoss: 0.533940\n",
      "\n",
      "Test set: Avg. loss: 0.2639, Accuracy: 9232/10000 (92%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'negative log likelihood loss')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')\n",
    "#fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
