{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from torchvision.utils import make_grid\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 3\n",
    "n_epochs_90 = 5\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRotation(object):\n",
    "    \"\"\"Rotate image by a fixed angle which is ready for tranform.Compose()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, degrees, resample=False, expand=False, center=None):\n",
    "        self.degrees = degrees\n",
    "        self.resample = resample\n",
    "        self.expand = expand\n",
    "        self.center = center\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \n",
    "        return transforms.ToTensor()(\n",
    "            transforms.functional.rotate(\n",
    "                transforms.ToPILImage()(img), \n",
    "                self.degrees, self.resample, self.expand, self.center))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation = 0 # Specifies the rotation of images.\n",
    "\n",
    "# Define the train and test loader\n",
    "# Here we are adding our CustomRotation function to the transformations\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               CustomRotation(rotation),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               CustomRotation(rotation),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data.shape\n",
    "#Is this where we get the size for the summary below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    #This defines the structure of the NN.\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()  #Dropout\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2)) #Convolutional Layer/Pooling Layer/Activation\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2)) #Convolutional Layer/Dropout/Pooling Layer/Activation\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x)) #Fully Connected Layer/Activation\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x) #Fully Connected Layer/Activation\n",
    "        return F.log_softmax(x, dim=1) #Softmax gets probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initalize the network & optimzer\n",
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(network, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create two lists for saving training and testing losses\n",
    "#On the x-axis we want to display the number of training examples the network has seen during training\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "                (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            #torch.save(network.state_dict(), '/results/model.pth')\n",
    "            #torch.save(optimizer.state_dict(), '/results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_viz(kernels, path=None, cols=None):\n",
    "    \"\"\"Visualize weight and activation matrices learned \n",
    "    during the optimization process. Works for any size of kernels.\n",
    "    \n",
    "    Arguments\n",
    "    =========\n",
    "    kernels: Weight or activation matrix. Must be a high dimensional\n",
    "    Numpy array. Tensors will not work.\n",
    "    path: Path to save the visualizations.\n",
    "    cols: TODO: Number of columns (doesn't work completely yet.)\n",
    "    \n",
    "    Example\n",
    "    =======\n",
    "    kernels = model.conv1.weight.cpu().detach().clone()\n",
    "    kernels = kernels - kernels.min()\n",
    "    kernels = kernels / kernels.max()\n",
    "    custom_viz(kernels, 'results/conv1_weights.png', 5)\n",
    "    \"\"\"\n",
    "    def set_size(w,h, ax=None):\n",
    "        \"\"\" w, h: width, height in inches \"\"\"\n",
    "        if not ax: ax=plt.gca()\n",
    "        l = ax.figure.subplotpars.left\n",
    "        r = ax.figure.subplotpars.right\n",
    "        t = ax.figure.subplotpars.top\n",
    "        b = ax.figure.subplotpars.bottom\n",
    "        figw = float(w)/(r-l)\n",
    "        figh = float(h)/(t-b)\n",
    "        ax.figure.set_size_inches(figw, figh)\n",
    "    \n",
    "    N = kernels.shape[0]\n",
    "    C = kernels.shape[1]\n",
    "\n",
    "    Tot = N*C\n",
    "\n",
    "    # If single channel kernel with HxW size,\n",
    "    # plot them in a row.\n",
    "    # Else, plot image with C number of columns.\n",
    "    if C>1:\n",
    "        columns = C\n",
    "    elif cols==None:\n",
    "        columns = N\n",
    "    elif cols:\n",
    "        columns = cols\n",
    "    rows = Tot // columns \n",
    "    rows += Tot % columns\n",
    "\n",
    "    pos = range(1,Tot + 1)\n",
    "\n",
    "    fig = plt.figure(1)\n",
    "    fig.tight_layout()\n",
    "    k=0\n",
    "    for i in range(kernels.shape[0]):\n",
    "        for j in range(kernels.shape[1]):\n",
    "            img = kernels[i][j]\n",
    "            ax = fig.add_subplot(rows,columns,pos[k])\n",
    "            ax.imshow(img, cmap='gray')\n",
    "            plt.axis('off')\n",
    "            k = k+1\n",
    "\n",
    "    set_size(30,30,ax)\n",
    "    if path:\n",
    "        plt.savefig(path, dpi=100)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = network.conv1.weight.cpu().detach().clone()\n",
    "kernels = kernels - kernels.min()\n",
    "kernels = kernels / kernels.max()\n",
    "custom_viz(kernels, None, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = network.conv2.weight.cpu().detach().clone()\n",
    "kernels = kernels - kernels.min()\n",
    "kernels = kernels / kernels.max()\n",
    "custom_viz(kernels, None, cols=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_tensor(_in_tensor, plot=True):\n",
    "    in_tensor = _in_tensor.clone()\n",
    "    # Add one more channel to the beginning. Tensor shape = 1,1,28,28\n",
    "    in_tensor.unsqueeze_(0)\n",
    "    # Convert to Pytorch variable\n",
    "    in_tensor = Variable(in_tensor, requires_grad=True)\n",
    "    \n",
    "    in_tensor_90 = in_tensor.transpose(2, 3).flip(3)\n",
    "    in_tensor_180 = in_tensor.flip(2).flip(3)\n",
    "    in_tensor_270 = in_tensor.transpose(2, 3).flip(2)\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure(1)\n",
    "        plt.subplot(221)\n",
    "        plt.gca().set_title('0 degree')\n",
    "        plt.imshow(in_tensor[0][0].cpu().detach().clone(), cmap='gray')\n",
    "        plt.subplot(222)\n",
    "        plt.gca().set_title('+90 degree')\n",
    "        plt.imshow(in_tensor_90[0][0].cpu().detach().clone(), cmap='gray')\n",
    "        plt.subplot(223)\n",
    "        plt.gca().set_title('+270 degree')\n",
    "        plt.imshow(in_tensor_270[0][0].cpu().detach().clone(), cmap='gray')\n",
    "        plt.subplot(224)\n",
    "        plt.gca().set_title('+180 degree')\n",
    "        plt.imshow(in_tensor_180[0][0].cpu().detach().clone(), cmap='gray')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return(in_tensor, in_tensor_90, in_tensor_180, in_tensor_270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number, number_90, number_180, number_270 = rotate_tensor(example_data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted Class: \", \n",
    "      np.argmax(network.forward(number).cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_out = network.conv1.forward(number)\n",
    "custom_viz(conv1_out.cpu().detach().clone(), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2_out = network.conv2.forward(conv1_out)\n",
    "custom_viz(conv2_out.cpu().detach().clone(), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation = 90 # Specifies the rotation of images.\n",
    "\n",
    "# Define the train and test loader\n",
    "# Here we are adding our CustomRotation function to the transformations\n",
    "\n",
    "train_loader_90 = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               CustomRotation(rotation),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader_90 = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               CustomRotation(rotation),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some example data from test loader\n",
    "examples_90 = enumerate(test_loader_90)\n",
    "batch_idx, (example_data_90, example_targets_90) = next(examples_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_90 = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create two lists for saving training and testing losses\n",
    "#On the x-axis we want to display the number of training examples the network has seen during training\n",
    "train_losses_90 = []\n",
    "train_counter_90 = []\n",
    "test_losses_90 = []\n",
    "test_counter_90 = [i*len(train_loader_90.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_90(epoch):\n",
    "    network_90.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader_90):\n",
    "        optimizer.zero_grad()\n",
    "        output = network_90(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader_90.dataset),\n",
    "            100. * batch_idx / len(train_loader_90), loss.item()))\n",
    "            train_losses_90.append(loss.item())\n",
    "            train_counter_90.append(\n",
    "                (batch_idx*64) + ((epoch-1)*len(train_loader_90.dataset)))\n",
    "            #torch.save(network.state_dict(), '/results/model.pth')\n",
    "            #torch.save(optimizer.state_dict(), '/results/optimizer.pth')\n",
    "\n",
    "def test_90():\n",
    "    network_90.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader_90:\n",
    "            output = network_90(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader_90.dataset)\n",
    "    test_losses_90.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader_90.dataset),\n",
    "        100. * correct / len(test_loader_90.dataset)))\n",
    "\n",
    "test_90()\n",
    "for epoch in range(1, n_epochs_90 + 1):\n",
    "    train_90(epoch)\n",
    "    test_90()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_counter_90, train_losses_90, color='blue')\n",
    "plt.scatter(test_counter_90, test_losses_90, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
